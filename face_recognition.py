# -*- coding: utf-8 -*-
"""Face Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T2rdmZ00pRIVGwT7sWoB5F66exStefZu
"""

import re
import numpy as np
from matplotlib import pyplot
import os
from numpy import linalg as LA 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn.preprocessing import StandardScaler  
from sklearn.decomposition import PCA
from google.colab import drive

##### Read pgm file ,converts it to a single row vector
def read_pgm(filename, byteorder='>'):
    
    with open(filename, 'rb') as f:
        buffer = f.read()
    try:
        header, width, height, maxval = re.search(
            b"(^P5\s(?:\s*#.*[\r\n])*"
            b"(\d+)\s(?:\s*#.*[\r\n])*"
            b"(\d+)\s(?:\s*#.*[\r\n])*"
            b"(\d+)\s(?:\s*#.*[\r\n]\s)*)", buffer).groups()
    except AttributeError:
        raise ValueError("Not a raw PGM file: '%s'" % filename)
    
    img = np.frombuffer(buffer,
                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',
                            count=int(width)*int(height),
                            offset=len(header)
                            ).reshape((int(height), int(width)))

    return img.reshape(1,int(height)*int(width))
  
  

##### Read single vector vector image, converts plot it
def plot_pgm(imgVec):
    # fixed image dimensions: 92x112
    img = imgVec.reshape(112, 92)
    pyplot.imshow(img, pyplot.cm.gray)
    pyplot.show()


##### read all image test cases to prepare Data matrix D and Label Vector Y
def generate_dataMatrix_labelVector():
   
    #generate data matrix and vector label
    drive.mount('/content/drive')
    path = "/content/drive/My Drive/Colab Notebooks/orl_faces"
    
    D = []
    label = []
    for i in range(1,41):   
        for j in range(1,11):
            img = pyplot.imread(path+"/s"+str(i)+"/"+str(j)+".pgm")
            #print("img shape: ",img.shape)
            #pyplot.imshow(img)
            D.append(np.array(img).flatten())
            label.append(i-1) 

    D = np.matrix(D) 
    Y = np.array(label)
    
    return D,Y


##### Spliting data into training and testing
def split_training_testing(dataMatrix, labelVector):
    # generate data matrix and vector label fro training and test
    dataTrain = np.array([])
    yTrain = np.array([])
    dataTest = np.array([])
    yTest = np.array([])

    # spliting: odd rows for training and even rows for testing
    for i in range(0, 400):
        if (i % 2 == 0):
            dataTest = np.append(dataTest, dataMatrix[i])
            yTest = np.append(yTest, labelVector[i])
        else:
            dataTrain = np.append(dataTrain, dataMatrix[i])
            yTrain = np.append(yTrain, labelVector[i])

    dataTrain = dataTrain.reshape(200, 10304)
    yTrain = yTrain.reshape(200, 1)
    dataTest = dataTest.reshape(200, 10304)
    yTest = yTest.reshape(200, 1)

    return dataTrain, yTrain, dataTest, yTest
  
def split_training_testing_Bonus(dataMatrix, labelVector):
    # generate data matrix and vector label fro training and test
    dataTrain = np.array([])
    yTrain = np.array([])
    dataTest = np.array([])
    yTest = np.array([])

    # spliting: 7 imgs for training and 3 imgs for testing
    for i in range(0,400,10):
        
        for j in range(i,i+3):
            dataTest = np.append(dataTest, dataMatrix[j])
            yTest = np.append(yTest, labelVector[j])
        
        i = i+3
        
        print (i)
        
        for j in range(i,i+7):
            dataTrain = np.append(dataTrain, dataMatrix[j])
            yTrain = np.append(yTrain, labelVector[j])
            
        i = i+7
            
    dataTrain = dataTrain.reshape(280, 10304)
    yTrain = yTrain.reshape(280, 1)
    dataTest = dataTest.reshape(120, 10304)
    yTest = yTest.reshape(120, 1)
    
    #print("yTrain")
    #print(yTrain)
    #print("yTest")
    #print(yTest)
    
    return dataTrain, yTrain, dataTest, yTest


########################################### Main function ##########################################################
if __name__ == "__main__":
    ### read image and convert it to a single vector
    # image = read_pgm("1.pgm", byteorder='<')
    # print(image)
    # print(image.size)

    ### plot image
    # plot_pgm(image)

    ### Generate data matrix and label vector
    D, Y = generate_dataMatrix_labelVector()
    # print (D)
    #plot_pgm(D[0])
    #plot_pgm(D[1])
    #print(Y)
    # print(Y[10])
    #print (D[0])

    ### split into traininng and testing
    dTrain, yTrain, dTest, yTest = split_training_testing(D, Y)
    #dTrain, yTrain, dTest, yTest = split_training_testing_Bonus(D, Y)
    #print(Dtrain[5])



##### Classification using PCA - returns Projection Matrix
  
    # We work on Training matrix to find projection matrix
    
    #feature scalling
    #scaler = StandardScaler().fit(dTrain)
    #dTrain = scaler.transform(dTrain)  
    #dTest = scaler.transform(dTest)
    

   
    #alpha = 0.8
    
    #calculate mean vector on D
    print("Mean")
    mean = np.mean(dTrain, axis=0).reshape(10304,1)
    print(mean)
    print(mean.shape)
    
    #Center data arround the mean
    print("Centered data")
    zTrain = dTrain - np.ones((200,1)).dot(mean.T)
    zTest  = dTest  - np.ones((200,1)).dot(mean.T)
    print("zTrain")
    print(zTrain)
    print(zTrain.shape)
    print("zTest")
    print(zTest)
    print(zTest.shape)
    
    #calculate covariance matrix
    print("Covariance matrix")
    #covarianceMatrix = np.cov(zTrain.T)
    covarianceMatrix = (1/len(zTrain)) * np.matmul(np.transpose(zTrain),zTrain)
    print(covarianceMatrix) 
      
    #calculate eigen values &vectors from cov matrix
    eigenValues,eigenVectors = LA.eigh(covarianceMatrix)  
    print("Eigen Values")
    print(eigenValues)
    print(eigenValues.shape)
    print("Eigen Vectors")
    print(eigenVectors)
    print(eigenVectors.shape)

#determine the number of reduced dimentionality for each alpha
   
alpha  = [ 0.8, 0.85, 0.9, 0.95 ]

kParam = [ 1, 3, 5, 7 ]
  
for k in alpha:
  
  print("Alpha Value -> ",k)
  i = 10303
  EigenVals = 0
  projectionMatrix = []

        #projection matrix for each alpha value
        #print("Eigen values chosen:")
  count = 0

  totalEigVals = 0
  
  for t in range(0,len(eigenValues)):
     
      totalEigVals= totalEigVals + eigenValues[t]

  while ((EigenVals/(totalEigVals)) <= k):
    
      EigenVals = EigenVals + eigenValues[i]
                #print(eigenValues[i])
      projectionMatrix.append(np.array(eigenVectors[:,i]))
      i = i - 1
      count += 1


  print("Eigen values used:")
  print(count)

        #print("Projection Matrix")
        #print(projectionMatrix)
    #    print(projectionMatrix.shape)


        #projection of training and test matrix
  print("Projection Data Train & Test")
  projectedDataTrain =  np.matmul(zTrain,np.transpose(projectionMatrix))
  projectedDataTest  =  np.matmul(zTest ,np.transpose(projectionMatrix))

       # print(projectedDataTrain.shape)
  print(projectedDataTest.shape)

        #Knn for each value of k
  for q in kParam:
          #use first nearest neighbour classifier
      knn = KNeighborsClassifier(n_neighbors=q)
      knn.fit(projectedDataTrain,yTrain)


      rowsValues_pred = knn.predict(projectedDataTest)
      rowsValues_pred1 = knn.predict(projectedDataTrain)

      print("k = ",q ,"Train Accuracy = ",accuracy_score(yTrain,rowsValues_pred1))
      print("k = ",q ,"Test  Accuracy = ",accuracy_score(yTest,rowsValues_pred))