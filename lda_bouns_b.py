# -*- coding: utf-8 -*-
"""LDA_Bouns_B.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J2ZsPmdKSgntWrXY6bRJ4K6-d2u70H-W
"""

import re
import numpy as np
from matplotlib import pyplot
import os
from google.colab import drive
from numpy import linalg as LA
import scipy as scipy
from google.colab import drive


##### Read pgm file ,converts it to a single row vector
def read_pgm(filename, byteorder='>'):
    with open(filename, 'rb') as f:
        buffer = f.read()
    try:
        header, width, height, maxval = re.search(
            b"(^P5\s(?:\s*#.*[\r\n])*"
            b"(\d+)\s(?:\s*#.*[\r\n])*"
            b"(\d+)\s(?:\s*#.*[\r\n])*"
            b"(\d+)\s(?:\s*#.*[\r\n]\s)*)", buffer).groups()
    except AttributeError:
        raise ValueError("Not a raw PGM file: '%s'" % filename)

    img = np.frombuffer(buffer,
                        dtype='u1' if int(maxval) < 256 else byteorder + 'u2',
                        count=int(width) * int(height),
                        offset=len(header)
                        ).reshape((int(height), int(width)))

    return img.reshape(1, int(height) * int(width))


##### Read single vector vector image, converts plot it
def plot_pgm(imgVec):
    # fixed image dimensions: 92x112
    img = imgVec.reshape(112, 92)
    pyplot.imshow(img, pyplot.cm.gray)
    pyplot.show()


##### read all image test cases to prepare Data matrix D and Label Vector Y
def generate_dataMatrix_labelVector():
    # generate data matrix and vector label
    dataMatrix = np.array([])
    yVector = np.array([])

    # fill D matrix and Y vector
    drive.mount('/content/drive')
    src = '/content/drive/My Drive/Colab Notebooks/orl_faces-bounsB'
   
    for d in os.listdir(src):
        path = "/" + os.path.basename(d)
        label = int(os.path.basename(d)[1:])
        # print(label)
        for f in os.listdir(src + path):
            # print (os.path.basename(f))
            img = read_pgm(src + path + "/" + os.path.basename(f), byteorder='<')
            dataMatrix = np.append(dataMatrix, img)
            # plot_pgm(img)
            yVector = np.append(yVector, label)

    dataMatrix = dataMatrix.reshape(200, 10304)
    yVector = yVector.reshape(200, 1)

    return dataMatrix, yVector
  
     
def split_training_testing_Bonus(dataMatrix, labelVector):
    # generate data matrix and vector label fro training and test
    dataTrain = np.array([])
    yTrain = np.array([])
    dataTest = np.array([])
    yTest = np.array([])

    # spliting: 80%(160) imgs for training and 20%(40) imgs for testing
    for i in range(0,200,5):
        
        for j in range(i,i+1):
            dataTest = np.append(dataTest, dataMatrix[j])
            yTest = np.append(yTest, labelVector[j])
        
        i = i+1
        
        print (i)
        
        for j in range(i,i+4):
            dataTrain = np.append(dataTrain, dataMatrix[j])
            yTrain = np.append(yTrain, labelVector[j])
            
        i = i+4
            
    dataTrain = dataTrain.reshape(160, 10304)
    yTrain = yTrain.reshape(160, 1)
    dataTest = dataTest.reshape(40, 10304)
    yTest = yTest.reshape(40, 1)
    
    #print("yTrain")
    #print(yTrain)
    #print("yTest")
    #print(yTest)
    
    return dataTrain, yTrain, dataTest, yTest
  
  ########################################### Main function ##########################################################
if __name__ == "__main__":
    ### read image and convert it to a single vector
    # image = read_pgm("1.pgm", byteorder='<')
    # print(image)
    # print(image.size)

    ### plot image
    # plot_pgm(image)

    ### Generate data matrix and label vector
    D, Y = generate_dataMatrix_labelVector()
    #print (D)
    #plot_pgm(D[150])
    #plot_pgm(D[1])
    #print(Y)
    # print(Y[10])
    #print (D[0])

    ### split into traininng and testing
    #Dtrain, Ytrain, Dtest, Ytest = split_training_testing(D, Y)
    Dtrain, Ytrain, Dtest, Ytest = split_training_testing_Bonus(D, Y)
    #print(Ytrain)
    #print(Ytrain.shape)
    #print(Ytest)
    
    #print(Dtrain[5])



###LDA
    my_dict_for_data = {}
    my_dict_for_mean = {}
    my_dict_for_class_scatter_matrix = {}
    total_mean = np.zeros((10304, 1))
    between_class_scatter_matrix = np.zeros((10304, 10304))
    mean_deviation = np.array([])
    mean_deviation_transpose = np.array([])
    #mean_deviation_product = np.array([])
    class_scatter_matrix = np.zeros((10304, 10304))
    within_class_scatter_matrix = np.zeros((10304, 10304))
    D = np.array([])
    mean = np.array([])
    #total_mean = np.array([])

    #peparing each data of a class in a matrix
    for z in range(0,160,80):
        D = Dtrain[range(z,z+80), :]
        print(D.shape)
        #D.reshape(5,10304)
        my_dict_for_data[str(Ytrain[z])] = D
        #print(str(Ytrain[z]))
        #print(D)


    #get the mean for each matrix
    for key in my_dict_for_data:

        #print(key, my_dict_for_data[key])
        #print("\n Mean Vector")
        mean = np.mean(my_dict_for_data[key], axis=0)
        mean = mean.reshape(10304,1)
        print(mean.shape)
        my_dict_for_mean[key] = mean
        print(key, my_dict_for_mean[key])
     
   # get the between-class scatter matrix (B)

  # compute the total mean
    for key in my_dict_for_mean:
        # print(my_dict_for_mean[key])
        # print(my_dict_for_mean[key].size)
        # print(total_mean)
        total_mean = total_mean + my_dict_for_mean[key]

    #total_mean = total_mean.reshape(10304, 1)
    print(total_mean.shape)
    total_mean = total_mean / 2
    # print("total mean")
    print(total_mean)

#compute SB
i = 0 
for key in my_dict_for_mean:
        i=i+1
        print(i)
        mean_deviation = my_dict_for_mean[key] - total_mean
        print(mean_deviation.shape)
        #mean_deviation = mean_deviation.reshape(10304, 1)
        mean_deviation_transpose = np.transpose(mean_deviation)
        print(mean_deviation_transpose.shape)
        #mean_deviation_transpose = mean_deviation_transpose.reshape(1, 10304)
        #mean_deviation_product = np.dot(mean_deviation, mean_deviation_transpose)
        #print(mean_deviation_product.shape)
        #mean_deviation_product = mean_deviation_product.reshape(10304, 10304)
        between_class_scatter_matrix = between_class_scatter_matrix + (80 * (np.dot(mean_deviation, mean_deviation_transpose)))
        print(between_class_scatter_matrix.shape)
        
#between_class_scatter_matrix = between_class_scatter_matrix.reshape(10304, 10304)
print("between_class_scatter_matrix")
print(between_class_scatter_matrix.shape)
print(between_class_scatter_matrix)

#compute class scatter matrix(s1,s2,s3,...)
temp1 = np.array([])
#temp2 = np.array([])
temp2_transpose = np.array([])
#deviation_point_from_its_mean = np.array([])
#deviation_point_from_its_mean_transpose = np.array([])
deviation_point_from_its_mean_product = np.array([])
i=0
for key in my_dict_for_data:
        i=i+1
        print(i)
        temp1 = my_dict_for_data[key]
        print("temp1",temp1.shape)
        print(temp1)
        for z in range(0, 80):
            temp2_transpose = np.transpose(temp1[z, :].reshape(1, 10304))
           
            deviation_point_from_its_mean_product = np.dot((temp2_transpose - my_dict_for_mean[key]),
                                                           (np.transpose(temp2_transpose - my_dict_for_mean[key])))
            class_scatter_matrix = class_scatter_matrix + deviation_point_from_its_mean_product
            
        within_class_scatter_matrix = within_class_scatter_matrix + class_scatter_matrix

inverse = np.linalg.inv(within_class_scatter_matrix)
print(inverse.shape)
w =np.dot(inverse,between_class_scatter_matrix) 
print(w.shape)
eig_vals, eig_vecs = scipy.linalg.eigh(w , eigvals=((10304-1),(10304-1)))
print("eignvalue")
print(eig_vals)
print("eigenVectors")
print(eig_vecs)

#projection of training and test matrix
    print("Projection Data Train & Test")
    projectedDataTrain = Dtrain.dot(eig_vecs) 
    projectedDataTest  = Dtest.dot(eig_vecs)
    
    print(projectedDataTrain.shape)
    print(projectedDataTest.shape)

import re
import pandas as pd
import pickle
from pprint import pprint
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

kParam = [ 1, 3, 5, 7 ]
#Knn for each value of k
for q in kParam:
      knn = KNeighborsClassifier(n_neighbors=q)  
      knn.fit(projectedDataTrain,Ytrain)
      rowsValues_pred1 = knn.predict(projectedDataTrain)
      rowsValues_pred = knn.predict(projectedDataTest)
      print("k = ",q , "Accuracy Train = " ,accuracy_score(Ytrain,rowsValues_pred1))
      print("k = ",q , "Accuracy Test= " ,accuracy_score(Ytest,rowsValues_pred))